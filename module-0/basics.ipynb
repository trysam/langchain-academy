{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "660ce795-9307-4c2c-98a1-beabcb36c740",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-0/basics.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/56295530-getting-set-up-video-guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef597741-3211-4ecc-92f7-f58023ee237e",
   "metadata": {},
   "source": [
    "# LangChain Academy\n",
    "\n",
    "Welcome to LangChain Academy! \n",
    "\n",
    "## Context\n",
    "\n",
    "At LangChain, we aim to make it easy to build LLM applications. One type of LLM application you can build is an agent. There’s a lot of excitement around building agents because they can automate a wide range of tasks that were previously impossible. \n",
    "\n",
    "In practice though, it is incredibly difficult to build systems that reliably execute on these tasks. As we’ve worked with our users to put agents into production, we’ve learned that more control is often necessary. You might need an agent to always call a specific tool first or use different prompts based on its state. \n",
    "\n",
    "To tackle this problem, we’ve built [LangGraph](https://langchain-ai.github.io/langgraph/) — a framework for building agent and multi-agent applications. Separate from the LangChain package, LangGraph’s core design philosophy is to help developers add better precision and control into agent workflows, suitable for the complexity of real-world systems.\n",
    "\n",
    "## Course Structure\n",
    "\n",
    "The course is structured as a set of modules, with each module focused on a particular theme related to LangGraph. You will see a folder for each module, which contains a series of notebooks. A video will accompany each notebook to help walk through the concepts, but the notebooks are also stand-alone, meaning that they contain explanations and can be viewed independently of the videos. Each module folder also contains a `studio` folder, which contains a set of graphs that can be loaded into [LangGraph Studio](https://github.com/langchain-ai/langgraph-studio), our IDE for building LangGraph applications.\n",
    "\n",
    "## Setup\n",
    "\n",
    "Before you begin, please follow the instructions in the `README` to create an environment and install dependencies.\n",
    "\n",
    "## Chat models\n",
    "\n",
    "In this course, we'll be using [Chat Models](https://python.langchain.com/v0.2/docs/concepts/#chat-models), which do a few things take a sequence of messages as inputs and return chat messages as outputs. LangChain does not host any Chat Models, rather we rely on third party integrations. [Here](https://python.langchain.com/v0.2/docs/integrations/chat/) is a list of 3rd party chat model integrations within LangChain! By default, the course will use [ChatOpenAI](https://python.langchain.com/v0.2/docs/integrations/chat/openai/) because it is both popular and performant. As noted, please ensure that you have an `OPENAI_API_KEY`.\n",
    "\n",
    "Let's check that your `OPENAI_API_KEY` is set and, if not, you will be asked to enter it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f9a52c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_openai langchain_core langchain_community tavily-python\n",
    "%pip install --quiet  langchain_google_genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c2a15227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv()\n",
    "# Get the OpenAI API key from the environment variable\n",
    "OPENAI_API_KEY = os.getenv(\"GENAI_API_KPI\")\n",
    "TAVILY_API_KEY = os.getenv(\"TAVILY_API_KPI\")\n",
    "\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a326f35b",
   "metadata": {},
   "source": [
    "[Here](https://python.langchain.com/v0.2/docs/how_to/#chat-models) is a useful how-do for all the things that you can do with chat models, but we'll show a few highlights below. If you've run `pip install -r requirements.txt` as noted in the README, then you've installed the `langchain-openai` package. With this, we can instantiate our `ChatOpenAI` model object. If you are signing up for the API for the first time, you should receive [free credits](https://community.openai.com/t/understanding-api-limits-and-free-tier/498517) that can be applied to any of the models. You can see pricing for various models [here](https://openai.com/api/pricing/). The notebooks will default to `gpt-4o` because it's a good balance of quality, price, and speed [see more here](https://help.openai.com/en/articles/7102672-how-can-i-access-gpt-4-gpt-4-turbo-gpt-4o-and-gpt-4o-mini), but you can also opt for the lower priced `gpt-3.5` series models. \n",
    "\n",
    "There are [a few standard parameters](https://python.langchain.com/v0.2/docs/concepts/#chat-models) that we can set with chat models. Two of the most common are:\n",
    "\n",
    "* `model`: the name of the model\n",
    "* `temperature`: the sampling temperature\n",
    "\n",
    "`Temperature` controls the randomness or creativity of the model's output where low temperature (close to 0) is more deterministic and focused outputs. This is good for tasks requiring accuracy or factual responses. High temperature (close to 1) is good for creative tasks or generating varied responses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e19a54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "gpt4o_chat = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "gpt35_chat = ChatOpenAI(model=\"gpt-3.5-turbo-0125\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95b88483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAI\n",
    "llm = GoogleGenerativeAI(model=\"models/gemini-1.5-flash\", google_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588942b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e21c6a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28450d1b",
   "metadata": {},
   "source": [
    "Chat models in LangChain have a number of [default methods](https://python.langchain.com/v0.2/docs/concepts/#runnable-interface). For the most part, we'll be using:\n",
    "\n",
    "* `stream`: stream back chunks of the response\n",
    "* `invoke`: call the chain on an input\n",
    "\n",
    "And, as mentioned, chat models take [messages](https://python.langchain.com/v0.2/docs/concepts/#messages) as input. Messages have a role (that describes who is saying the message) and a content property. We'll be talking a lot more about this later, but here let's just show the basics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b1280e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello there!\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "# Create a message\n",
    "msg = HumanMessage(content=\"Hello world\", name=\"Lance\")\n",
    "\n",
    "# Message list\n",
    "messages = [msg]\n",
    "\n",
    "# Invoke the model with a list of messages \n",
    "llm.invoke(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac73e4c",
   "metadata": {},
   "source": [
    "We get an `AIMessage` response. Also, note that we can just invoke a chat model with a string. When a string is passed in as input, it is converted to a `HumanMessage` and then passed to the underlying model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f27c6c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The most common way to say thank you in Yoruba is **E se pupo** (Ẹ̀ṣẹ́ púpọ̀).  This translates literally to \"Thank you very much.\"  You can also use **Ope** (Ọ̀pẹ́) which is a shorter, more informal thank you.\\n'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"How do you say thank you in Yoruba?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdc2f0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 9, 'prompt_tokens': 9, 'total_tokens': 18}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-c75d3f0f-2d71-47be-b14c-42b8dd2b4b08-0', usage_metadata={'input_tokens': 9, 'output_tokens': 9, 'total_tokens': 18})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt35_chat.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582c0e5a",
   "metadata": {},
   "source": [
    "The interface is consistent across all chat models and models are typically initialized once at the start up each notebooks. \n",
    "\n",
    "So, you can easily switch between models without changing the downstream code if you have strong preference for another provider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad0069a",
   "metadata": {},
   "source": [
    "## Search Tools\n",
    "\n",
    "You'll also see [Tavily](https://tavily.com/) in the README, which is a search engine optimized for LLMs and RAG, aimed at efficient, quick, and persistent search results. As mentioned, it's easy to sign up and offers a generous free tier. Some lessons (in Module 4) will use Tavily by default but, of course, other search tools can be used if you want to modify the code for yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "091dff13",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52d69da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "tavily_search = TavilySearchResults(max_results=10)\n",
    "search_docs = tavily_search.invoke(\"What congnitive questions are there?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d06f87e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'url': 'https://www.practiceaptitudetests.com/cognitive-ability-tests/',\n",
       "  'content': '456 questions. Cognitive ability tests are predictors of general intelligence. Like IQ tests, they examine your ability to solve problems and think logically, via verbal, numerical, mechanical, spatial and logical questions. Cognitive tests are popular with employers, as the broad range of aptitudes covered can give a good overview of each'},\n",
       " {'url': 'https://www.webmd.com/brain/what-is-a-cognitive-test',\n",
       "  'content': 'There are many different cognitive tests available. Your provider will pick the most relevant to you, depending on your situation. All of the cognitive tests involve answering questions or'},\n",
       " {'url': 'https://www.practicereasoningtests.com/practice-cognitive-ability-test',\n",
       "  'content': 'Cognitive function tests are commonly employed in several contexts, including education, clinical psychology, neuropsychology and employment assessment. This cognitive ability practice test has been designed to help you prepare for the real thing. The test consists of a set of 10 questions, along with correct answers and full explanations.'},\n",
       " {'url': 'https://bigthink.com/mind-brain/free-cognitive-tests/',\n",
       "  'content': 'The Wonderlic Test—wonderfully named after its creator, Eldon F. Wonderlic—includes 50 questions designed to measure overall cognitive ability, or intelligence.'},\n",
       " {'url': 'https://www.testhq.com/blog/cognitive-ability-tests',\n",
       "  'content': 'Cognitive Ability assessments are useful in that they can be given to a large number of people and the results will highlight the candidates with the best cognitive skills. There is also superior cognitive ability testing, which is carried out in schools. They are designed to measure your overall cognitive ability by asking you questions on topics such as numerical reasoning, verbal reasoning'},\n",
       " {'url': 'https://www.jobtestprep.com/cognitive-ability-test',\n",
       "  'content': \"By combining questions of varying complexity from several fields with a stressful time limit, the cognitive ability test challenges the candidate's problem solving and processing speed abilities, and provides the employer with a measurement of general cognitive ability - a central component of intelligence.. Cognitive testing is such a popular hiring process tool because it is one of the most\"},\n",
       " {'url': 'https://aptitude-test.com/aptitude-tests/cognitive-ability/',\n",
       "  'content': 'It consists of 50 questions to be completed within a 15-minute time limit, covering mathematical ability, verbal reasoning, and vocabulary. Revelian Cognitive Ability Test (RCAT) The RCAT is a timed multiple-choice test that measures general cognitive ability. The test includes 51 questions to be answered within a time limit of 20 minutes.'},\n",
       " {'url': 'https://www.practicereasoningtests.com/cognitive-ability-tests',\n",
       "  'content': 'There are several versions of the test, and the one you take depends on your job role and company, making it challenging to prepare for. However, they all have common themes, which make your preparation easier. Take the time to research and understand your test and complete as many cognitive ability questions as possible.'},\n",
       " {'url': 'https://www.123test.com/cognitive-ability-test/',\n",
       "  'content': 'Here are free examples of the ten most frequently used cognitive tests: Numerical reasoning test. Verbal reasoning test. Logical reasoning test. Diagrammatic reasoning test. Spatial reasoning test. Inductive reasoning test. Deductive reasoning test. Mechanical reasoning test.'},\n",
       " {'url': 'https://my.clevelandclinic.org/health/articles/22306-cognitive-test',\n",
       "  'content': 'Some treatable or reversible conditions that affect mental functioning include:\\nPossible partially reversible causes of memory loss and cognitive impairment include:\\nCommon and nonreversible causes of memory loss and brain function changes include:\\nAdditional Common Questions\\nCan I test my cognitive ability myself?\\n Symptoms of mild cognitive impairment include:\\nWhat’s a neuropsychological assessment?\\nA neuropsychological assessment is an in-depth test given by a trained professional (a neuropsychologist). Your healthcare provider can:\\nWhat is mild cognitive impairment?\\nCognitive impairment means you have a problem with cognition (processing thoughts). Others include the Memory Impairment Screen (MIS)/MIS by Telephone (MIS-T), Mental Status Questionnaire (MSQ), 8-item Informant Interview (AD8), Functional Activities Questionnaire (FAQ), 7-Minute Screen (7MS), Abbreviated Mental Test (AMT), St Louis University Mental Status Examination (SLUMS), Telephone Instrument for Cognitive Status (TICS) and Informant Questionnaire on Cognitive Decline in the Elderly (IQCODE).\\n Taking an at-home cognitive test is a reasonable first step if you think you or a loved one is having trouble with memory, language, problem-solving and thinking.\\n'}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd7d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
